{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Part 2\n",
        "\n",
        "Build a date parser using basic text processing and rules. (No ML models)\n",
        "\n",
        "- Dataset:\n",
        "\n",
        "[date_parser_testcases.csv](https://prod-files-secure.s3.us-west-2.amazonaws.com/2ad6026b-7cdc-4780-99a4-6e4e0034cf90/aabbc537-a7c4-478b-ba8a-2afc146a8d23/date_parser_testcases.csv)\n",
        "\n",
        "- Given a piece of text, extract the day, month and year info and present it in DD/MM/YYYY format.\n",
        "    - Example: “I went to London on 21st June, 2024” → 21/06/2024\n",
        "- Use only default python packages and regex (no ML models OR external libraries)\n"
      ],
      "metadata": {
        "id": "b_5dHYMrbjzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import re\n",
        "\n",
        "# Load the dataset\n",
        "def load_dataset(file_path):\n",
        "    with open(file_path, mode='r') as file:\n",
        "        reader = csv.reader(file)\n",
        "        data = list(reader)\n",
        "    return data\n",
        "\n",
        "# Preprocess text\n",
        "def preprocess_text(text):\n",
        "    text = text.lower().strip()\n",
        "    return text\n",
        "\n",
        "# Extract date components using regex\n",
        "def extract_date(text):\n",
        "    # Define regex patterns for date components\n",
        "    day_pattern = r'\\b(?:0?[1-9]|[12][0-9]|3[01])\\b'\n",
        "    month_pattern = r'\\b(?:january|february|march|april|may|june|july|august|september|october|november|december|0?[1-9]|1[0-2])\\b'\n",
        "    year_pattern = r'\\b\\d{4}\\b'\n",
        "\n",
        "    day_match = re.search(day_pattern, text)\n",
        "    month_match = re.search(month_pattern, text)\n",
        "    year_match = re.search(year_pattern, text)\n",
        "\n",
        "    if not (day_match and month_match and year_match):\n",
        "        return None  # Return None for dates that cannot be parsed\n",
        "\n",
        "    day = day_match.group()\n",
        "    month = month_match.group()\n",
        "    year = year_match.group()\n",
        "\n",
        "    # Convert month name to month number\n",
        "    month_names = {\n",
        "        'january': '01', 'february': '02', 'march': '03', 'april': '04',\n",
        "        'may': '05', 'june': '06', 'july': '07', 'august': '08', 'september': '09',\n",
        "        'october': '10', 'november': '11', 'december': '12'\n",
        "    }\n",
        "\n",
        "    if month.isdigit():\n",
        "        month = month.zfill(2)\n",
        "    else:\n",
        "        month = month_names.get(month, '01')\n",
        "\n",
        "    # Ensure day and year are in the correct format\n",
        "    day = day.zfill(2)\n",
        "\n",
        "    return f\"{day}/{month}/{year}\"\n",
        "\n",
        "# Process the dataset\n",
        "def process_dates(file_path):\n",
        "    data = load_dataset(file_path)\n",
        "    processed_dates = []\n",
        "\n",
        "    for row in data:\n",
        "        text = preprocess_text(row[0])  # Assuming text is in the first column\n",
        "        date_str = extract_date(text)\n",
        "        if date_str is not None:  # Only include non-null dates\n",
        "            processed_dates.append(date_str)\n",
        "\n",
        "    return processed_dates\n",
        "\n",
        "# Example usage\n",
        "file_path = '/content/date_parser_testcases.csv'\n",
        "dates = process_dates(file_path)\n",
        "\n",
        "for date in dates:\n",
        "    print(date)\n"
      ],
      "metadata": {
        "id": "3fxgz_wja6KT",
        "outputId": "6abbd4b5-7ef5-4d08-afff-34459c764620",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "05/03/2023\n",
            "07/07/1990\n",
            "12/12/2022\n",
            "02/02/2022\n",
            "11/11/1987\n",
            "03/04/2020\n",
            "05/05/1997\n",
            "11/11/2021\n",
            "08/08/2021\n",
            "10/10/1995\n",
            "01/01/2023\n",
            "03/03/2022\n",
            "31/08/2020\n",
            "02/02/2020\n",
            "12/12/2019\n",
            "17/03/2022\n",
            "11/11/2021\n",
            "07/07/2023\n",
            "09/09/2021\n",
            "01/01/2022\n",
            "10/10/2022\n",
            "10/10/2018\n",
            "12/12/2020\n",
            "31/12/2022\n",
            "29/02/2024\n",
            "07/07/2021\n",
            "03/03/2022\n",
            "08/08/2020\n",
            "09/09/2020\n",
            "01/01/2022\n",
            "07/07/2023\n",
            "05/05/1990\n",
            "05/03/2023\n",
            "07/07/1990\n",
            "12/12/2022\n",
            "02/02/2022\n",
            "11/11/1987\n",
            "03/04/2020\n",
            "11/11/2021\n",
            "08/08/2021\n",
            "10/10/1995\n",
            "01/01/2023\n",
            "03/03/2022\n",
            "31/08/2020\n",
            "02/02/2020\n",
            "12/12/2019\n",
            "17/03/2022\n",
            "11/11/2021\n",
            "07/07/2023\n",
            "09/09/2021\n",
            "01/01/2022\n",
            "10/10/2022\n",
            "10/10/2018\n",
            "12/12/2020\n",
            "31/12/2022\n",
            "29/02/2024\n",
            "07/07/2021\n",
            "03/03/2022\n",
            "08/08/2020\n",
            "09/09/2020\n",
            "01/01/2022\n",
            "07/07/2023\n",
            "05/05/1990\n"
          ]
        }
      ]
    }
  ]
}